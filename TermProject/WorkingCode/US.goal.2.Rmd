---
title: 'Goal 2 Univaraite: US'
author: "Jaclyn Coate & Josh Eysenbach"
date: "7/31/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tswge)
library(ggplot2)
library(ggthemes)
```

# US COVID Data

### Data Prep
In order to prep our data from our EDA we will load, transform the date, remove all zero row from the variable we are testing *hospitalizedCurrently*, and sort from oldest to newet. This will allow us to easily work through our univariate time series evaluations.

```{r load data}
us <- read.csv("https://raw.githubusercontent.com/JaclynCoate/6373_Time_Series/master/TermProject/Data/USdaily.7.26.20.csv", header = T, strip.white = T)
us <- transform(us, date = as.Date(as.character(date), "%Y%m%d"))
us <- subset(us, select = -c(states, dateChecked, hospitalized, lastModified, total, posNeg, totalTestResultsIncrease, hash))
us[is.na(us)] <- 0
#Selecting only those dates with reported current hospitilizations
us <- dplyr::slice(us,1:132)
us = us[order(as.Date(us$date, format = "%Y%m%d")),]
head(us)
```

### Stationarity: Current Hospitalizations
It is difficult to assume stationarity for this data due to multiple factors. We are working under the assumption that COVID is a novel virus and cases as well as hospitalizations will eventually return to zero. This being said our current modeling techniques do things such as return to the median or mimic the previously seen trends. Also, we see a heavy wandering trend in both new cases and hospitalization would be dependent on this as well as time. We will review the data and see what, if any, non-stationary components reveal themselves and model the data accordingly.

## Univariate AR/ARMA Modeling

1.  Original Realization Analysis
Traits:
- Heavy wandering behavior 
- What appears to be some noise that could be pseudo-cyclic behavior hidden by the large numbers.

```{r}
ggplot(data = us, aes(x=date, y=hospitalizedCurrently))+
  geom_line(color="orange")+
  labs(title = "Current COVID Hospitalized Cases US", y = "Thousands", x = "") +
    theme_fivethirtyeight()
```

2. Sample Realization, ACF, and Spectral Density
Realization:
  - Heavy wandering behavior 
  - Possible small pseudo-cyclic behavior

ACF:

  - Very slowly dampening behavior that would be consistent with a d=1 ARIMA model.

Spectral Density:

  - Peak at f=0
  - What appears to be a wave through the rest of the graph- this could be a hidden seasonality or another frequency peak that is hidden by the pseudo-cyclic behavior mentioned in above the realization above.

```{r}
plotts.sample.wge(us$hospitalizedCurrently, lag.max = 100)
```

3. Overfit tables
- Since we are seeing heavy wandering behavior, we will use overfit tables to see if we can surface any (1-B) factors that have roots very near the unit circle. 

  - Below we are able to clearly see 1: (1-B) factor that has a root nearly on the Unit Circle.

```{r}
est.ar.wge(us$hospitalizedCurrently,p=6,type='burg')
```

4. Difference the data based on surfaced (1-B) Factor
- Once the data has been differenced, we see something that looks much closer to a stationary data set. However, we have also surfaced what appears to be a small seasonality component. We see the ACF have higher spikes surface at 7 and 14, which would lead us to believe there is a 7-day seasonal component.

```{r}
us.diff = artrans.wge(us$hospitalizedCurrently, phi.tr = 1, lag.max = 100)
acf(us.diff)
```

5. Seasonality Transformation
- Above we have surfaced what appears to be a 7-day seasonality trend. We will now transform the data for the s=7.

```{r}
us.diff.seas = artrans.wge(us.diff,phi.tr = c(0,0,0,0,0,0,1), lag.max = 100)
```

6. Diagnose Model w/ aic.wge
- When we diagnose the best models to use for our stationary data set, we see the R AIC5 function selects an AIC ARMA(5,1) model while the BIC selects a AR(2). The AR(2) model is consistent with our pseudo-cyclic data as well as the dampening cyclical sample autocorrelations that are produced by the transformed data. The ARMA(5,1) could also produce these same traits. We will move forward and compare these two models.

```{r}
aic5.wge(us.diff.seas)
aic5.wge(us.diff.seas,type = "bic")
```

7. Diagnose white noise
- Both of the Junge Box test show us that we reject the H null with p-values that are < 0.05 alpha significance level.

```{r}
ljung.wge(us.diff.seas)$pval
ljung.wge(us.diff.seas, K=48)$pval
```

8. Estimate Phis and Thetas
- AIC Phi and Theta Estimates

```{r}
est.us.diff.seasAIC = est.arma.wge(us.diff.seas, p = 5, q=1)
mean(us$hospitalizedCurrently)
```

- BIC Phi Estimates

```{r}
est.us.diff.seasBIC = est.arma.wge(us.diff.seas, p = 2)
mean(us$hospitalizedCurrently)
```

### Univariate ARIMA(5,1,1), s=7 Forecasting

- 7-Day Forecast

```{r}
shortARMA <- fore.aruma.wge(us$hospitalizedCurrently, phi = est.us.diff.seasAIC$phi, theta = est.us.diff.seasAIC$theta, d= 1, s = 7, n.ahead = 7, lastn = F, limits = T)
```

- AIC

```{r}
est.us.diff.seasAIC$aic
```

- Windowed ASE: 14,880,281

```{r, fig.show="hide", warning=FALSE}
phis = est.us.diff.seasAIC$phi
thetas = est.us.diff.seasAIC$theta

trainingSize = 24
horizon = 7
ASEHolder = numeric()

for( i in 1:(124-(trainingSize + horizon) + 1))
{
  forecasts = fore.aruma.wge(us$hospitalizedCurrently[i:(i+(trainingSize-1))],phi = phis, theta = thetas, s = 7, d = 1, n.ahead = horizon)
  
  ASE = mean((us$hospitalizedCurrently[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - forecasts$f)^2)
         
  ASEHolder[i] = ASE
}
```

```{r}
invisible(ASEHolder)
hist(ASEHolder)
WindowedASE = mean(ASEHolder)

summary(ASEHolder)
WindowedASE
```

- ASE: 73,605,156

```{r}
fs = fore.aruma.wge(us$hospitalizedCurrently[i:(i+(trainingSize+horizon)-1)],phi = phis, theta = thetas, s = 7, d = 1,n.ahead = 7, lastn = TRUE)
ASE = mean((us$hospitalizedCurrently[(i+trainingSize):(i+(trainingSize+horizon)-1)] - fs$f )^2)
ASE
```

- 90-Day Forecast

```{r}
longARMA <- fore.aruma.wge(us$hospitalizedCurrently, phi = est.us.diff.seasAIC$phi, theta = est.us.diff.seasAIC$theta, d= 1, s = 7, n.ahead = 90, lastn = F, limits = F)
```

- Windowed ASE: 18,103,000,000

```{r, fig.show="hide", warning=FALSE}
phis = est.us.diff.seasAIC$phi
thetas = est.us.diff.seasAIC$theta

trainingSize = 24
horizon = 90
ASEHolder = numeric()

for( i in 1:(124-(trainingSize + horizon) + 1))
{
  forecasts = fore.aruma.wge(us$hospitalizedCurrently[i:(i+(trainingSize-1))],phi = phis, theta = thetas, s = 7, d = 1,n.ahead = horizon)
  
  ASE = mean((us$hospitalizedCurrently[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - forecasts$f)^2)
         
  ASEHolder[i] = ASE
}
```

```{r}
invisible(ASEHolder)
hist(ASEHolder)
WindowedASE = mean(ASEHolder)

summary(ASEHolder)
WindowedASE
```

- ASE: 108,278,159

```{r}
fs = fore.aruma.wge(us$hospitalizedCurrently[i:(i+(trainingSize+horizon)-1)],phi = phis, theta = thetas, s = 7, d = 1, n.ahead = 90, lastn = T)
ASE = mean((us$hospitalizedCurrently[(i+trainingSize):(i+(trainingSize+horizon)-1)] - fs$f )^2)
ASE
```

### Univariate ARIMA(2,1,0), s=7 Forecasting

- 7-Day Forecast

```{r}
shortAR <- fore.aruma.wge(us$hospitalizedCurrently, phi = est.us.diff.seasBIC$phi, d=1, s=7, n.ahead = 7, lastn = FALSE, limits = FALSE)
```

  - AIC

```{r}
est.us.diff.seasBIC$aic
```

  - Windowed ASE: 15,546,758

```{r, fig.show="hide", warning=FALSE}
phis = est.us.diff.seasBIC$phi
thetas = est.us.diff.seasBIC$theta

trainingSize = 24
horizon = 7
ASEHolder = numeric()

for( i in 1:(124-(trainingSize + horizon) + 1))
{
  forecasts = fore.aruma.wge(us$hospitalizedCurrently[i:(i+(trainingSize-1))],phi = phis, theta = thetas, s = 7, d = 1, n.ahead = horizon)
  
  ASE = mean((us$hospitalizedCurrently[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - forecasts$f)^2)
         
  ASEHolder[i] = ASE
}
```

```{r}
invisible(ASEHolder)
hist(ASEHolder)
WindowedASE = mean(ASEHolder)

summary(ASEHolder)
WindowedASE
```

  - ASE: 60,809,514

```{r}
fs = fore.aruma.wge(us$hospitalizedCurrently[i:(i+(trainingSize+horizon)-1)],phi = phis, theta = thetas, s = 7, d = 1,n.ahead = 7, lastn = TRUE)
ASE = mean((us$hospitalizedCurrently[(i+trainingSize):(i+(trainingSize+horizon)-1)] - fs$f )^2)
ASE
```

- 90 Day Forecast

```{r}
longAR <- fore.aruma.wge(us$hospitalizedCurrently, phi = est.us.diff.seasBIC$phi, s= 7, d = 1, n.ahead = 90, lastn = FALSE, limits = FALSE)
```

  - Windowed ASE: 19,427,666,679

```{r, fig.show="hide", warning=FALSE}
phis = est.us.diff.seasBIC$phi
thetas = est.us.diff.seasBIC$theta

trainingSize = 24
horizon = 90
ASEHolder = numeric()

for( i in 1:(124-(trainingSize + horizon) + 1))
{
  forecasts = fore.aruma.wge(us$hospitalizedCurrently[i:(i+(trainingSize-1))],phi = phis, theta = thetas, s = 7, d = 1,n.ahead = horizon)
  
  ASE = mean((us$hospitalizedCurrently[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - forecasts$f)^2)
         
  ASEHolder[i] = ASE
}
```

```{r}
ASEHolder
hist(ASEHolder)
WindowedASE = mean(ASEHolder)

summary(ASEHolder)
WindowedASE
```

  - ASE: 185,865,366

```{r}
fs = fore.aruma.wge(us$hospitalizedCurrently[i:(i+(trainingSize+horizon)-1)],phi = phis, theta = thetas, s = 7, d = 1,n.ahead = 90, lastn = TRUE)
ASE = mean((us$hospitalizedCurrently[(i+trainingSize):(i+(trainingSize+horizon)-1)] - fs$f )^2)
ASE
```

## Univariate Multilayered Perceptron (MLP) / Neural Network Model
For our univariate NN model we created a training and test data set. This allows us to cross validate our model performance. This is our first NN model and will be used with mostly default parameters. This is to see how our mlp function does in producing a model with few settings. However, with such little data we are also curious how leveraging all of the data changes the trend on the forecast. So, we will model them side by side to see the difference on what the forecasts produce.

1. Creating train / test data set

```{r}
library(nnfor)
head(us)
usTrain.nn = ts(us$hospitalizedCurrently[1:125])
```

2. Fitting NN model
  a. Fitted model on train data set. While we will continue to build on model on the train data set to get our ASE etc. We did want to see how 7 days can change  We did this to see just how different merely 7 days can mean to a model.

```{r}
us.nn.fit = mlp(usTrain.nn, outplot = T, comb = "mean", m=7, reps = 50)
plot(us.nn.fit)
```

  b. Fitted a model on the full data set. It shows that the same model is developed but we want to see how this affects our forecast. We suspect a data point up or down can drastically change the trend of the forecast.
  
```{r}
us.nn.fit2 = mlp(ts(us$hospitalizedCurrently), outplot = T, comb = "mean", m=7, reps = 50)
plot(us.nn.fit2)
```

3. Forecast horizon/step forward
  a. With just the trained data set being used we see a slightly trend upward in the 7-day forecast. However, the 90 day forecast is showing a much larger lift in trend towards the end of the forecast. We see a large lift in numbers. We also see the plausible range for the possibilities is also high. The NN models give us a glimpse into how difficult it is to forecast something like COVID hospitalization cases. With such limited data, and the lack of ability to know if we've completed a full 'cycle' for predictions against leaves us with many possible outcomes and the NN forecast shows us this by the large range of possible outcomes and the mean in blue in the center. 
  - 7-Day Forecast
    
```{r}
us.nn.fit.fore7 = forecast(us.nn.fit, h=7)
plot(us.nn.fit.fore7)
```

  - 90-Day Forecast

```{r}
us.nn.fit.fore90 = forecast(us.nn.fit, h=90)
plot(us.nn.fit.fore90)
```

  b. For the 7-day forecast we still see an extensive range for the NN models, we do see a change in trend for full data set than the trained. We can see that those extra days of showing a downward trend project instead of a flat level for COVID hospitalized patients. This would be essentially a difference in being able to reduce supplies versus needing supplies to remain the same. This is important to take into account and means a daily update of the model would be needed to accurately forecast any future trend or predictions. For the 90-day forecast we see a similar change in trend. For the 90-day forecast based on the trained data set we expect to see a large increase in trend for the 90-day forecast. This could be useful, however, seems like it is performing directly opposite to what we expect from novel virus. 
  - 7 Day Forecast

```{r}
us.nn.fit.fore2 = forecast(us.nn.fit2, h=7)
plot(us.nn.fit.fore2)
```

  - 90-Day Forecast

```{r}
us.nn.fit.fore2 = forecast(us.nn.fit2, h=90)
plot(us.nn.fit.fore2)
```

4. Plot forecast against test set
  
```{r}
plot(us$hospitalizedCurrently[126:132], type = "l", ylim = c(55000, 80000))
lines(seq(1:7), us.nn.fit.fore7$mean, col = "blue")
```

5. ASE: 1,302,298
  -7-Day
```{r}
ASEus.nn.fit.fore7 = mean((us$hospitalizedCurrently[126:132]-us.nn.fit.fore7$mean)^2)
ASEus.nn.fit.fore7
```
  -90-Day
```{r}
ASEus.nn.fit.fore90 = mean((us$hospitalizedCurrently[43:132]-us.nn.fit.fore90$mean)^2)
ASEus.nn.fit.fore90
```

### MLP NN Model Analysis
We completed a default neural network model. With so many opportunities for how to actually tune neural network model we knew this would not be our best model in this case. So, we moved forward with a hyper tuned neural network model for our ensemble model that allows us to calculate many windowed ASEs and compare those models against each other.

## Ensemble Model / Hyper tuned NN Model

```{r}
library(tswgewrapped)
```

1. Train / Test Data Sets

```{r}
data_train.u <- data.frame(hospitalizedCurrently = us$hospitalizedCurrently[1:122], positiveIncrease = rnorm(122, 0, .0001))
data_test.u <- data.frame(hospitalizedCurrently = us$hospitalizedCurrently[123:132], positiveIncrease = rnorm(10, 0, .0001))
```

2. Hyper tune parameters
- Here we are running specialty function contained in tswgewrapped package that allows us to perform a grid search that will complete the tuning of all parameters to obtain the one with the lowest windowed ASE.

```{r}
# search for best NN hyperparameters in given grid
model.u = tswgewrapped::ModelBuildNNforCaret$new(data = data_train.u, var_interest = "hospitalizedCurrently",
                                               search = 'random', tuneLength = 5, parallel = TRUE,
                                               batch_size = 50, h = 7, m = 7,
                                               verbose = 1)
```

3. The windowed ASEs associated with the grid of hyperparameters is shown in the table and heatmap below.

```{r}
res.u <- model.u$summarize_hyperparam_results()
res.u
```

```{r}
model.u$plot_hyperparam_results()
```

4. Best Parameters shown in below table. The best hyperparameters based on this grid search are 16 repetitions and 1 hidden layer, and allow.det.season = FALSE.

```{r}
best.u <- model.u$summarize_best_hyperparams()
best.u
```

5. Windowed ASE of 12,177,586.

```{r}
final.ase.u <- dplyr::filter(res.u, reps == best.u$reps &
                    hd == best.u$hd &
                    allow.det.season == best.u$allow.det.season)[['ASE']]
final.ase.u
```

6. Ensemble model characteristics and plot

```{r}
# Ensemble / Hypertuned NN Model
caret_model.u = model.u$get_final_models(subset = 'a')
caret_model.u$finalModel
```

```{r}
#Plot Final Model
plot(caret_model.u$finalModel)
```

7. Train ensemble model
  - Since we came across an interesting outcome with our nn default model above when we reviewed the forecasts on the trained data vs full data set; we will do the same with our hypertuned parameters ensemble model.
  a. First we build our ensemble model on the trained data set.

```{r}
#Ensemble model trained data
ensemble.mlp.u1 = nnfor::mlp(usTrain.nn, outplot = T, reps = 16, hd = 1, allow.det.season = F)
ensemble.mlp.u1
```

  b. Next we build our model on the entirity data set. 

```{r}
#Ensemble model
ensemble.mlp.u2 = nnfor::mlp(ts(us$hospitalizedCurrently), outplot = T, reps = 16, hd = 1, allow.det.season = F)
ensemble.mlp.u2
```

  - 7-Day
  a. First we will 7-day forecast our trained data set. As we can see we see a flattening of the forecast over the next 7 days witha  slight downward trend.. 

```{r}
fore7.1.u = forecast(ensemble.mlp.u1 , h=7)
plot(fore7.1.u)
```

  b. Next we forecasted the 7-day for our full data set. We see a much strong downward trend in our 7 day forecast.
  
```{r}
fore7.2.u = forecast(ensemble.mlp.u2, h=7)
plot(fore7.2.u)
```

  - 90-Day
  a. With our 90-day trained data set forecast we see a very strong downward trend. With a possibility of a variation of this trend being a little less straight (shown by the shadowed line that is slightly higher than the highlighted blue mean).

```{r}
fore90.1.u = forecast(ensemble.mlp.u1, h=90)
plot(fore90.1.u)
```

  b. Full data set. We see a clear downward trend and that the COVID hospitalized cases will eventually reach zero. The possibilities all stay closely to the mean and there doesn't seem to be much of a chance of a deviation from this model.

```{r}
fore90.2.u = forecast(ensemble.mlp.u2, h=90)
plot(fore90.2.u)
```

## Model Analysis
Upon completion of the above models we can see that the most important take away is that each data point is essential in determining the trend of the COVID virus. We can see that with cross validation methods we can see a trend but as each of those data points become a piece of the model the trend alters day by day. It will be essential moving forward that models are update daily to be able to acquire a good trend and therefore ability to forecast the needs for hospitalizes and the severity of COVID moving forward.

When investigating these models, it became clear that the 90-day forecasts were simply repeating the trend and seasonality without much extrapolation that we would recommend using for long term forecast. We would only recommend using the short 7 day forecast for predicting hospital equipment and staffing needs. The ensemble model had the lowest windowed ASE and is what we recommend moving forward for these short term forecasts.

## Univariate Model Performance Breakdown
### ARIMA(5,1,1), s=7 Forecasting
- 7-Day Windowed ASE
  - 14,880,281

- 90-Day Windowed ASE
  - 18,103,000,000

### ARIMA(2,1,0), s=7 Forecasting
- 7-Day Windowed ASE
    - 15,546,758

- 90-Day Windowed ASE
    - 19,427,666,679

### Default Neural Network Model
- 7-Day ASE
  - 1,511,391
- 90-Day ASE
  - 844,457,147

### Ensemble Model: Hyper Tuned Neural Network Model
- 7-Day Windowed ASE
  - 12,177,586
