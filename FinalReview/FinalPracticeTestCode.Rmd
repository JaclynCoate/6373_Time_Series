---
title: "FinalPracticeTest"
author: "Jaclyn A Coate"
date: "8/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# MLE examples
## Unit 9
### 9.3 Estimation: Maximum Likelihood Estimation - MLE
- Model: ARMA(2,1) (1-1.6B+.8B^2)(X_t-50) = (1-.8B)*a_t, sigma^2_a=5

```{r}
#Generating data for model
x21=gen.arma.wge(n=100,phi=c(1.6,-.8),theta=.8,vara=5,sn=55)

# gen.arma generates data from a zero 
x21=x21+50 

# mean model. We use this strategy to generate the
# AR(2) model with mean 50. 
est.arma.wge(x21,p=2,q=1)
```

```{r}
#Estimates of the phi
est.arma.wge(x21,p=2,q=1)$phi

#Estiamtes of the white noise variance / residuals (sigma_a^2)
est.arma.wge(x21,p=2,q=1)$avar

#Estimate of th emoving average parameter
est.arma.wge(x21,p=2,q=1)$theta

#Estimate of the mean
mean(x21)
```

- Model: AR(4) (1+.7B^2-.1B^3+.72B^4) (X_t-20) = a_t, sigma_a^2 = 10

```{r}
x40=gen.arma.wge(n=100,phi=c(0,-.7,.1,-.72),vara=10,sn=72)
x40=x40+20 
est.ar.wge(x40,p=4,type='mle')
# or you could use est.arma.wge(x40,p=4)
mean(x40)

#Estimates of the phi
est.ar.wge(x40,p=4,type='mle')$phi

#Estiamtes of the white noise variance / residuals (sigma_a^2)
est.ar.wge(x40,p=4,type='mle')$avar
```

- Concept Check 9.3 Tile 3
  - Model: ARMA(2, 1) (-1.3B+.7B^2) (X_t-37) = (1+.4B) a_t sigma_a^2 = 4

```{r}
cc9.3=gen.arma.wge(n=100,phi=c(.3,-.7),theta=-.4,vara=4)

# gen.arma generates data from a zero 
cc9.3=cc9.3+37

mean(cc9.3)
est.arma.wge(cc9.3,p=2,q=1)$avar
est.arma.wge(cc9.3,p=2,q=1)$phi
est.arma.wge(cc9.3,p=2,q=1)$theta
```

## 9.5 Estimation: Burg Estimates
### Maximum Likelihood (ML), Yule Walker, Burg Estiamtes
- tswge function est.ar.wge computes the following types of estimates
  - Generate Data from AR(2): (1-1.6B+.9B^2) X_t = a_t
  
```{r}
x9.5=gen.arma.wge(n=200,phi=c(1.6,-.9),vara=2,sn=33)
```

```{r}
x.mle=est.ar.wge(x9.5,p=2,type='mle')
x.mle
x.mle$avar #white noise variance
```

```{r}
x.yw=est.ar.wge(x9.5,p=2,type='yw')
x.yw
x.yw$phi
```

```{r}
x.burg=est.ar.wge(x9.5,p=2,type='burg')
```

```{r}
plotts.sample.wge(x9.5)
```

- Concept Check 9.5 Tile 7 & 8
  - Consider the model: (1-.3B+.7B^2) (X_t-37) = (1+.4B)a_t, sigma_a ^2 = 4
  - 7. What are the Burge and Yule Walker estiamtes: there are non because the Burg and Yule Walker estimates can only be for AR models.
  - 8. Now find ML esitamtes using above model
  
```{r}
x9.5.2=gen.arma.wge(n=200,phi=c(.3,-.7), theta = -0.4, vara = 4,sn=27)

x.mle.9.5.2=est.ar.wge(x9.5.2,p=4,type='mle')
x.mle.9.5.2
x.mle.9.5.2$avar #white noise variance
x.mle.9.5.2$phi
```

## 9.6 Estimation: When It Makes A Difference
- How to compare these estimates and when it matters

```{r}
x9.6=gen.arma.wge(n=100,phi=c(2.195,-1.994,.796), sn=53)
x9.6.yw=est.ar.wge(x9.6,p=3,type="yw")
x9.6.burg=est.ar.wge(x9.6,p=3,type="burg")
x.mle=est.ar.wge(x9.6,p=3,type="mle")
```

## 9.7 Estimation: White Noise Variance
- tswge estimates white noise variance/residuals (sigma_a^2) using the "backcast" residuals. 

```{r}
#Generate data from AR(3) model
x9.7=gen.arma.wge(n=100,phi=c(2.195,-1.994,.796), sn=53)
#Find MLE estiatmes of this mode
x.mle9.7=est.ar.wge(x9.7,p=3,type='mle')
#Check out white noise variance estimator
x.mle9.7
x.mle9.7$avar
#Note that the "residuals" are the a_hats found by backcasting
#Avar is the mean of these squared residuals (the variance assuming zero mean)
mean(x.mle9.7$res^2)
x.mle9.7$avar
```

# Final Practice Test

Consider the data in the file: FinalExamData.csv.  This file contains a column Xt and a column Zt.  Your goal is to simply model this data the using a vector autoregressive model (VAR) and a multi-layer perceptron model (MLP).  You ultimately want to forecast Xt with a horizon of 10 using Zt if it is useful.  Provide the following information in your response: 

```{r}
library(tswge)
library(vars)
library(nnfor)
library(forecast)
```

```{r}
final <- read.csv("https://raw.githubusercontent.com/BivinSadler/MSDS-6373-Time-Series/master/Unit%2015%20Final%20Exam/FinalExamData.csv", header = T)
head(final)
```

a.	Identify the relationship/association between Xt and Zt.  Specifically, is there evidence of a relationship/association between Xt and a lagged Zt? … if so, what is the lag?)  What evidence do you have to support this relationship/association?  (4 pts)

```{r}
ccf(final$Zt, final$Xt)
```

b.	For each model (MLR w/ Correlated Errors / VAR / MLP) (10 pts each model):
i.	Provide the code you used to fit the model and make the predictions. 

### MLR w/ Correlated Errors
- Forecast Zt Variable

```{r}
#Graph data for stationarity. There does not appear to be any violations of the 3 conditions
plotts.sample.wge(final$Zt)
#Diagnose model with aic5.wge
aic5.wge(final$Zt) #AIC picks MA(1)
aic5.wge(final$Zt, type = "bic") #BIC picks MA(1)
#Test for white noise
ljung.wge(final$Zt)$pval #FTR Ho
ljung.wge(final$Zt, K = 48)$pval #FTR 
#Going w/ MA(1)
#Estimate phis and thetas w/ est.arma.wge
Zt.est = est.arma.wge(final$Zt, p = 0, q = 1)
predsZt = fore.arma.wge(final$Zt, theta = Zt.est$theta , n.ahead = 10)
#Plote predictions
plot(predsZt$f, type = "l", col = "red")
#Graph Zt realization and 10 predictions
plot(seq(1,95,1), final$Zt, type = "l", xlim = c(0,105))
lines(seq(96,105,1), predsZt$f, type = "l", col = "red")
```

OR 

```{r}
#MLP can be used to create predictions
#Create a time series object
tsZt <- ts(final$Zt)
#Fit MLP
fit.Zt <- nnfor::mlp(tsZt, reps = 50, comb = "mean")
fit.Zt
fore.Zt <- forecast::forecast(fit.Zt, h=10)
plot(fore.Zt)
fore.Zt$mean
```

- Model Xt variable predicted Zt variable using MLR with Cor Erros
- We know there is a lag of -5

```{r}
#Lag Zt 5
final$lagZt = dplyr::lag(final$Zt,5)
final
```

- Create trend
```{r}
#t=1:95
#final$t = t
```

- Fit simple model w/ lagged Zt and Time (t)

```{r}
lmfit = lm(Xt~lagZt, data = final) #+t if needing trend
```

- Check residuals
  - Reveal a frequency of .18, period 1/.18
```{r}
plotts.sample.wge(lmfit$residuals)
acf(lmfit$residuals)
ljung.wge(lmfit$residuals[6:85])
ljung.wge(lmfit$residuals[6:85], K=48)
```

- Surface seasonality of 5.5, going to round up to 6 and difference data

```{r}
trans.resid <- artrans.wge(lmfit$residuals, c(0,0,0,0,0,1))
plotts.sample.wge(trans.resid)
acf(trans.resid)
```

- Diagnose fit and determine the phis and thetas on resdidauls from transformed data
  - AIC Selects ARMA(7,1)

```{r}
phisthetas = aic.wge(trans.resid, p = 0:8, q = 0:8)
phisthetas
```

- Fit the arima model based on above fit
  - Seasonality from residual transformation above, for below equation

```{r}
fitarima = arima(final$Xt, order = c(7,0,1), seasonal = list(order = c(1,0,0), period = 6), xreg = final$lagZt)
fitarima
```

- AIC of fitted ARIMA

```{r}
AIC(fitarima)
```

```{r}
predsXt = predict(fitarima, newxreg = fore.Zt$mean, n.ahead = 10) #add cbind(, time) if trend sign
predsXt
```

```{r}
#Add predictions onto Zt column
#Ztwpreds <- data.frame(c(final$Zt, fore.Zt$mean))
#Ztwpreds
#time <- data.frame(c(final$t, t=96:105))
#time
```

#### VAR
- Graph Data
  - Upon grpahing the data we do not see extreme evidence of nonstationary components. We see that conditions 1 - 3 are tentatively met. We will assume stationarity.

```{r}
plotts.sample.wge(final$Zt)
plotts.sample.wge(final$Xt)
```

- Using VARselect diagnose the data
  -AIC = 2.303725 for p = 7

```{r}
VARselect(cbind(final$Xt, final$Zt),lag.max = 10, type = "both")
```

- Predictions with p=7

```{r}
VARp7 = VAR(cbind(final$Xt, final$Zt), type = "both", p = 7)
predsp7 = predict(VARp7, n.ahead = 10)
forecasts10 <- as.data.frame(predsp7$fcst$y1)
```

#### MLP
- Train / Test Data Sets

```{r}
nntrain <- data.frame(Xt = final$Xt[0:85], Zt = final$Zt[0:85])
nntest <- data.frame(Xt = final$Xt[86:95], Zt = final$Zt[86:95])
```

- Create ts series for model

```{r model best nn parameters}
tsnntrainXt = ts(nntrain$Xt)
tsnntrainZt = ts(nntrain$Zt)
```

- Fit model on Zt regressor and find 10 day predictions 

```{r}
fit.mlp.Zt = nnfor::mlp(tsnntrainZt, outplot= T, comb = "mean")
fit.mlp.Zt
mlp.new.fore7 = forecast::forecast(fit.mlp.Zt, h = 10)
mlp.new.fore7
```

- Combine observed new cases + forecast new cases

```{r}
Ztregress <- data.frame(c(nntrain$Zt, mlp.new.fore7$mean))
Ztregress
```

- Fit model for Xt w/ regressor of Zt

```{r}
mlp.Xt.fit = nnfor::mlp(tsnntrainXt, xreg=data.frame(tsnntrainZt), comb = "mean", xreg.lags = 5)
plot(mlp.Xt.fit)
```

ii.	Provide a plot of the 10 forecasts (time points 96 – 105).  You do not need prediction intervals for this question. 

#### MLR
- Plot Predictions

```{r}
plot(seq(1,95,1), final$Xt, type = "l", xlim = c(0,105))
lines(seq(96,105,1), predsXt$pred, type = "l", col = "dark red")
```

#### VAR 
- Plot predictions w/ observed

```{r}
plot(seq(1,95,1), final$Xt, type = "l", ylim = c(15,47), xlim = c(0,106))
lines(seq(96,105,1), forecasts10$fcst, type = "l", col= "red")
```

#### MLP
  - Xt 10 Day Forecast w/ Zt Regressor

```{r}
Xtfore10 = forecast::forecast(mlp.Xt.fit, h = 10, xreg = Ztregress)
plot(Xtfore10)
```

iii.	Find the ASE for each model using the last 10 observations of the dataset.  Include your code for this as well. 

#### MLR
- ASE

```{r}
ASEmlr = mean((final$Xt[86:95] - predsXt$pred)^2)
ASEmlr 
```

#### VAR
- ASE

```{r}
ASEvar = mean((final$Xt[86:95] - forecasts10$fcst)^2)
ASEvar
```

#### MLP
- ASE

```{r}
ASEmlp = mean((final$Xt[86:95] - Xtfore10$mean)^2)
ASEmlp
```


c.	Make a quick statement about which model you feel is most useful and why.  (4 pts)
